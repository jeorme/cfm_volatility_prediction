{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon May 14 01:30:12 2018\n",
    "\n",
    "@author: xshitova\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn import datasets, linear_model, metrics \n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "#uploading the files with data \n",
    "input_train=pd.read_csv('C:/Users/xshitova/Downloads/training_input.csv', delimiter=';')\n",
    "output_train=pd.read_csv('C:/Users/xshitova/Downloads/challenge_output_data_training_file_volatility_prediction_in_financial_markets.csv', delimiter=';') \n",
    "\n",
    "input_test=pd.read_csv('C:/Users/xshitova/Downloads/testing_input.csv', delimiter=';')\n",
    "\n",
    "#note to self - the train and the test are actually of the same size \n",
    "\n",
    "#column names in inputs \n",
    "#ID is the name of the line and primary key here\n",
    "cols=[\"ID\",\"date\",\"product_id\",\"volatility 09:30:00\",\"volatility 09:35:00\",\"volatility 09:40:00\",\n",
    "      \"volatility 09:45:00\",\"volatility 09:50:00\",\"volatility 09:55:00\",\"volatility 10:00:00\",\"volatility 10:05:00\",\n",
    "      \"volatility 10:10:00\",\"volatility 10:15:00\",\"volatility 10:20:00\",\"volatility 10:25:00\",\"volatility 10:30:00\",\n",
    "      \"volatility 10:35:00\",\"volatility 10:40:00\",\"volatility 10:45:00\",\"volatility 10:50:00\",\"volatility 10:55:00\",\n",
    "      \"volatility 11:00:00\",\"volatility 11:05:00\",\"volatility 11:10:00\",\"volatility 11:15:00\",\"volatility 11:20:00\",\n",
    "      \"volatility 11:25:00\",\"volatility 11:30:00\",\"volatility 11:35:00\",\"volatility 11:40:00\",\"volatility 11:45:00\",\n",
    "      \"volatility 11:50:00\",\"volatility 11:55:00\",\"volatility 12:00:00\",\"volatility 12:05:00\",\"volatility 12:10:00\",\n",
    "      \"volatility 12:15:00\",\"volatility 12:20:00\",\"volatility 12:25:00\",\"volatility 12:30:00\",\"volatility 12:35:00\",\n",
    "      \"volatility 12:40:00\",\"volatility 12:45:00\",\"volatility 12:50:00\",\"volatility 12:55:00\",\"volatility 13:00:00\",\n",
    "      \"volatility 13:05:00\",\"volatility 13:10:00\",\"volatility 13:15:00\",\"volatility 13:20:00\",\"volatility 13:25:00\",\n",
    "      \"volatility 13:30:00\",\"volatility 13:35:00\",\"volatility 13:40:00\",\"volatility 13:45:00\",\"volatility 13:50:00\",\n",
    "      \"volatility 13:55:00\",\n",
    "      \"return 09:30:00\",\"return 09:35:00\",\"return 09:40:00\",\"return 09:45:00\",\"return 09:50:00\",\"return 09:55:00\",\n",
    "      \"return 10:00:00\",\"return 10:05:00\",\"return 10:10:00\",\"return 10:15:00\",\"return 10:20:00\",\"return 10:25:00\",\n",
    "      \"return 10:30:00\",\"return 10:35:00\",\"return 10:40:00\",\"return 10:45:00\",\"return 10:50:00\",\"return 10:55:00\",\n",
    "      \"return 11:00:00\",\"return 11:05:00\",\"return 11:10:00\",\"return 11:15:00\",\"return 11:20:00\",\"return 11:25:00\",\n",
    "      \"return 11:30:00\",\"return 11:35:00\",\"return 11:40:00\",\"return 11:45:00\",\"return 11:50:00\",\"return 11:55:00\",\n",
    "      \"return 12:00:00\",\"return 12:05:00\",\"return 12:10:00\",\"return 12:15:00\",\"return 12:20:00\",\"return 12:25:00\",\n",
    "      \"return 12:30:00\",\"return 12:35:00\",\"return 12:40:00\",\"return 12:45:00\",\"return 12:50:00\",\"return 12:55:00\",\n",
    "      \"return 13:00:00\",\"return 13:05:00\",\"return 13:10:00\",\"return 13:15:00\",\"return 13:20:00\",\"return 13:25:00\",\n",
    "      \"return 13:30:00\",\"return 13:35:00\",\"return 13:40:00\",\"return 13:45:00\",\"return 13:50:00\",\"return 13:55:00\"]\n",
    "\n",
    "#column names in outputs \n",
    "cols1=[\"ID\",\"TARGET\"]\n",
    "mis_val_count_train=list()\n",
    "mis_val_count_test=list()\n",
    "\n",
    "#need to print the name of the column and how many empty values it has (for all the columns in input, test and train)\n",
    "for i in range(0,111):\n",
    "    print(cols[i]+\"     \"+str(input_train[cols[i]].isnull().sum())+\" empty values\")\n",
    "    mis_val_count_train.append(input_train[cols[i]].isnull().sum()) #creating a list and storing count of missing values in there \n",
    "    \n",
    "print(\"\")  \n",
    " \n",
    "for i in range(0,111):\n",
    "    print(cols[i]+\"     \"+str(input_test[cols[i]].isnull().sum())+\" empty values\")\n",
    "    mis_val_count_test.append(input_test[cols[i]].isnull().sum()) #creating a list and \n",
    "\n",
    "#plotting missing values - two overlapping graphs (to more easily visualize how much data is missing)  \n",
    "plt.figure(figsize=(22, 10))\n",
    "plt.plot(mis_val_count_train,  color='blue')\n",
    "plt.plot(mis_val_count_test, color='red')\n",
    "plt.xticks(np.arange(111),cols) #without arange it will give a mistake as the text is not sequenced\n",
    "plt.xticks(rotation=60) \n",
    "plt.rc('xtick',labelsize=10)\n",
    "plt.show()\n",
    "\n",
    "#count unique products in train \n",
    "print(str(input_train['product_id'].nunique())+\" unique products in train\")\n",
    "#count unique products in test \n",
    "print(str(input_test['product_id'].nunique())+\" unique products in test\")\n",
    "#count unique days in train\n",
    "print(str(input_train['date'].nunique())+\" unique days in train\")\n",
    "#count unique days in test\n",
    "print(str(input_test['date'].nunique())+\" unique days in test\")\n",
    "\n",
    "#taking all the volatilities for each line and calculating their mean\n",
    "col = input_test.loc[: , \"volatility 09:30:00\":\"volatility 13:55:00\"]\n",
    "input_test['volatility_mean'] = col.mean(axis=1)\n",
    "\n",
    "#creating a dataframe for output of a required length \n",
    "output_test=pd.concat([input_test['ID'],input_test['volatility_mean']], axis=1)\n",
    "\n",
    "#exporting the output into a file\n",
    "output_test.to_csv('C:/Users/xshitova/Downloads/submission1.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    " \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
